{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ethdCvIq6rhk",
        "outputId": "12d4e675-372f-4277-943c-777e61a88347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tatrach-autoformer-main.zip\n",
            "   creating: tatrach-autoformer-main/\n",
            "  inflating: tatrach-autoformer-main/.gitignore  \n",
            "   creating: tatrach-autoformer-main/dataset/\n",
            "  inflating: tatrach-autoformer-main/dataset/Data_TaTrach.csv  \n",
            "   creating: tatrach-autoformer-main/dataset/ETT-small/\n",
            "  inflating: tatrach-autoformer-main/dataset/ETT-small/ETTh1.csv  \n",
            "   creating: tatrach-autoformer-main/data_provider/\n",
            "  inflating: tatrach-autoformer-main/data_provider/data_factory.py  \n",
            "  inflating: tatrach-autoformer-main/data_provider/data_loader.py  \n",
            " extracting: tatrach-autoformer-main/data_provider/__init__.py  \n",
            "  inflating: tatrach-autoformer-main/Dockerfile  \n",
            "  inflating: tatrach-autoformer-main/environment.yml  \n",
            "   creating: tatrach-autoformer-main/exp/\n",
            "  inflating: tatrach-autoformer-main/exp/exp_basic.py  \n",
            "  inflating: tatrach-autoformer-main/exp/exp_main.py  \n",
            " extracting: tatrach-autoformer-main/exp/__init__.py  \n",
            "   creating: tatrach-autoformer-main/layers/\n",
            "  inflating: tatrach-autoformer-main/layers/AutoCorrelation.py  \n",
            "  inflating: tatrach-autoformer-main/layers/Autoformer_EncDec.py  \n",
            "  inflating: tatrach-autoformer-main/layers/Embed.py  \n",
            "  inflating: tatrach-autoformer-main/layers/SelfAttention_Family.py  \n",
            "  inflating: tatrach-autoformer-main/layers/Transformer_EncDec.py  \n",
            " extracting: tatrach-autoformer-main/layers/__init__.py  \n",
            "  inflating: tatrach-autoformer-main/LICENSE  \n",
            "  inflating: tatrach-autoformer-main/Makefile  \n",
            "   creating: tatrach-autoformer-main/models/\n",
            "  inflating: tatrach-autoformer-main/models/Autoformer.py  \n",
            "  inflating: tatrach-autoformer-main/models/Informer.py  \n",
            "  inflating: tatrach-autoformer-main/models/Reformer.py  \n",
            "  inflating: tatrach-autoformer-main/models/Transformer.py  \n",
            " extracting: tatrach-autoformer-main/models/__init__.py  \n",
            "   creating: tatrach-autoformer-main/pic/\n",
            "  inflating: tatrach-autoformer-main/pic/Auto-Correlation.png  \n",
            "  inflating: tatrach-autoformer-main/pic/Autoformer.png  \n",
            "  inflating: tatrach-autoformer-main/pic/results.png  \n",
            "  inflating: tatrach-autoformer-main/predict.ipynb  \n",
            "  inflating: tatrach-autoformer-main/README.md  \n",
            "  inflating: tatrach-autoformer-main/requirements.txt  \n",
            "  inflating: tatrach-autoformer-main/run.py  \n",
            "   creating: tatrach-autoformer-main/scripts/\n",
            "   creating: tatrach-autoformer-main/scripts/ECL_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/ECL_script/Autoformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ECL_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ECL_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ECL_script/Transformer.sh  \n",
            "   creating: tatrach-autoformer-main/scripts/ETT_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Autoformer_ETTh1.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Autoformer_ETTh2.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Autoformer_ETTm1.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Autoformer_ETTm2.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Autoformer_univariate.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ETT_script/Transformer.sh  \n",
            "   creating: tatrach-autoformer-main/scripts/Exchange_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/Exchange_script/Autoformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Exchange_script/Autoformer_univariate.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Exchange_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Exchange_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Exchange_script/Transformer.sh  \n",
            "   creating: tatrach-autoformer-main/scripts/ILI_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/ILI_script/Autoformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ILI_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ILI_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/ILI_script/Transformer.sh  \n",
            "   creating: tatrach-autoformer-main/scripts/Traffic_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/Traffic_script/Autoformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Traffic_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Traffic_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Traffic_script/Transformer.sh  \n",
            "   creating: tatrach-autoformer-main/scripts/Weather_script/\n",
            "  inflating: tatrach-autoformer-main/scripts/Weather_script/Autoformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Weather_script/Informer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Weather_script/Reformer.sh  \n",
            "  inflating: tatrach-autoformer-main/scripts/Weather_script/Transformer.sh  \n",
            "  inflating: tatrach-autoformer-main/tatrach.ipynb  \n",
            " extracting: tatrach-autoformer-main/tatrach.rar  \n",
            "   creating: tatrach-autoformer-main/utils/\n",
            "  inflating: tatrach-autoformer-main/utils/download_data.py  \n",
            "  inflating: tatrach-autoformer-main/utils/masking.py  \n",
            "  inflating: tatrach-autoformer-main/utils/metrics.py  \n",
            "  inflating: tatrach-autoformer-main/utils/timefeatures.py  \n",
            "  inflating: tatrach-autoformer-main/utils/tools.py  \n",
            " extracting: tatrach-autoformer-main/utils/__init__.py  \n"
          ]
        }
      ],
      "source": [
        "!unzip tatrach-autoformer-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt6iq6kB7vRn",
        "outputId": "26eac0b5-bda3-423a-835d-3233e9b0a0d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reformer-pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from reformer-pytorch)\n",
            "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from reformer-pytorch) (0.8.1)\n",
            "Collecting local-attention (from reformer-pytorch)\n",
            "  Downloading local_attention-1.11.2-py3-none-any.whl.metadata (929 bytes)\n",
            "Collecting product-key-memory (from reformer-pytorch)\n",
            "  Downloading product_key_memory-0.2.11-py3-none-any.whl.metadata (717 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from reformer-pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->reformer-pytorch) (3.4.0)\n",
            "Collecting hyper-connections>=0.1.8 (from local-attention->reformer-pytorch)\n",
            "  Downloading hyper_connections-0.2.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting colt5-attention>=0.10.14 (from product-key-memory->reformer-pytorch)\n",
            "  Downloading CoLT5_attention-0.11.1-py3-none-any.whl.metadata (737 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from colt5-attention>=0.10.14->product-key-memory->reformer-pytorch) (25.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->reformer-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->reformer-pytorch) (3.0.2)\n",
            "Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
            "Downloading local_attention-1.11.2-py3-none-any.whl (9.5 kB)\n",
            "Downloading product_key_memory-0.2.11-py3-none-any.whl (6.5 kB)\n",
            "Downloading CoLT5_attention-0.11.1-py3-none-any.whl (18 kB)\n",
            "Downloading hyper_connections-0.2.1-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: hyper-connections, axial-positional-embedding, local-attention, colt5-attention, product-key-memory, reformer-pytorch\n",
            "Successfully installed axial-positional-embedding-0.3.12 colt5-attention-0.11.1 hyper-connections-0.2.1 local-attention-1.11.2 product-key-memory-0.2.11 reformer-pytorch-1.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"tatrach-autoformer-main\")\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "from exp.exp_main import Exp_Main#exp stands for experiments\n",
        "import random\n",
        "import numpy as np\n",
        "from utils.tools import dotdict"
      ],
      "metadata": {
        "id": "cZM1gJdP7vUL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def config_param(num_units,batch_size,learning_rate,dropout_rate):\n",
        "    args = dotdict()\n",
        "    args.target = 'OT'\n",
        "    args.des = 'test'\n",
        "    args.dropout = dropout_rate\n",
        "    args.num_workers = 10\n",
        "    args.gpu = 0\n",
        "    args.lradj = 'type1'\n",
        "    args.devices = '0'\n",
        "    args.use_gpu = True\n",
        "    args.use_multi_gpu = False\n",
        "    # if args.use_gpu and args.use_multi_gpu: #是否使用多卡的判断\n",
        "    #     args.dvices = args.devices.replace(' ', '')\n",
        "    #     device_ids = args.devices.split(',')\n",
        "    #     args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    #     args.gpu = args.device_ids[0]\n",
        "    args.freq = 'h'\n",
        "    args.checkpoints = './checkpoints/'\n",
        "    args.bucket_size = 4\n",
        "    args.n_hashes = 4\n",
        "    args.seq_len = 24\n",
        "    args.label_len = 24\n",
        "    args.pred_len = 24\n",
        "    args.e_layers = 2\n",
        "    args.d_layers = 1\n",
        "    args.n_heads = 8\n",
        "    args.factor = 1\n",
        "    args.d_model = num_units\n",
        "    args.des = 'Exp'\n",
        "    args.itr = 1\n",
        "    args.d_ff = 2048\n",
        "    args.moving_avg = 25\n",
        "    args.distil = True\n",
        "    args.output_attention = False\n",
        "    args.patience= 3\n",
        "    args.learning_rate = learning_rate\n",
        "    args.batch_size = batch_size\n",
        "    args.embed = 'timeF'\n",
        "    args.activation = 'gelu'\n",
        "    args.use_amp = False\n",
        "    args.loss = 'mse'\n",
        "\n",
        "    args.train_epochs = 1\n",
        "    args.is_training = True\n",
        "    args.enc_in = 1\n",
        "    args.dec_in = 1\n",
        "    args.c_out = 1\n",
        "    args.target = \"q64\"\n",
        "    args.root_path = './dataset'\n",
        "    args.data_path ='mucnuoc_gio_preprocess1.csv'\n",
        "    args.model_id='q64'\n",
        "    args.model = 'Autoformer'\n",
        "    #args.model = 'Informer'\n",
        "    args.data = 'custom'\n",
        "    args.features = 'S'\n",
        "\n",
        "    print('Args in experiment:')\n",
        "    print(args)\n",
        "\n",
        "    Exp = Exp_Main\n",
        "    return args"
      ],
      "metadata": {
        "id": "WrejTf6n7vWy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainning(args):\n",
        "    Exp = Exp_Main\n",
        "    if args.is_training:\n",
        "      for ii in range(args.itr):\n",
        "          # setting record of experiments\n",
        "          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "              args.model_id,\n",
        "              args.model,\n",
        "              args.data,\n",
        "              args.features,\n",
        "              args.seq_len,\n",
        "              args.label_len,\n",
        "              args.pred_len,\n",
        "              args.d_model,\n",
        "              args.n_heads,\n",
        "              args.e_layers,\n",
        "              args.d_layers,\n",
        "              args.d_ff,\n",
        "              args.factor,\n",
        "              args.embed,\n",
        "              args.distil,\n",
        "              args.des, ii)\n",
        "\n",
        "          exp = Exp(args)  # set experiments\n",
        "          print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "          exp.train(setting)\n",
        "\n",
        "          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "          mae, rmse, r2=exp.test(setting)\n",
        "\n",
        "          if args.do_predict:\n",
        "              print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "              exp.predict(setting, True)\n",
        "          torch.cuda.empty_cache()\n",
        "          return mae, rmse, r2\n",
        "    else:\n",
        "      ii = 0\n",
        "      setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(args.model_id,\n",
        "                                                                                                    args.model,\n",
        "                                                                                                    args.data,\n",
        "                                                                                                    args.features,\n",
        "                                                                                                    args.seq_len,\n",
        "                                                                                                    args.label_len,\n",
        "                                                                                                    args.pred_len,\n",
        "                                                                                                    args.d_model,\n",
        "                                                                                                    args.n_heads,\n",
        "                                                                                                    args.e_layers,\n",
        "                                                                                                    args.d_layers,\n",
        "                                                                                                    args.d_ff,\n",
        "                                                                                                    args.factor,\n",
        "                                                                                                    args.embed,\n",
        "                                                                                                    args.distil,\n",
        "                                                                                                    args.des, ii)\n",
        "\n",
        "      exp = Exp(args)  # set experiments\n",
        "      print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "      exp.test(setting, test=1)\n",
        "      torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "EAFltat97vaj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Danh sách các tham số để thử nghiệm\n",
        "param_grid = {\n",
        "    \"num_units\": [32, 64],  # Số nơ-ron trong LSTM\n",
        "    \"batch_size\": [32,64],  # Kích thước batch\n",
        "    \"learning_rate\": [0.01,0.001],  # Learning rate\n",
        "    \"dropout_rate\": [0.2, 0.5],\n",
        "}\n",
        "\n",
        "# Lưu kết quả của từng bộ tham số\n",
        "results = []\n",
        "\n",
        "# Grid Search\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Đang huấn luyện với tham số: {params}\")\n",
        "\n",
        "    # Xây dựng mô hình\n",
        "\n",
        "    args=config_param(params[\"num_units\"],params[\"batch_size\"],params[\"learning_rate\"],params[\"dropout_rate\"])\n",
        "\n",
        "    # Cấu hình optimizer\n",
        "    mae, rmse, r2=trainning(args)\n",
        "    # Lưu kết quả\n",
        "    results.append((params, rmse,r2))\n",
        "\n",
        "# Tìm bộ tham số tốt nhất\n",
        "best_params = sorted(results, key=lambda x: x[1])[0]\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Tìm bộ tham số tốt nhất\n",
        "best_params = sorted(results, key=lambda x: x[2])[0]\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7jmNbAd-duC",
        "outputId": "af539c2f-ee53-497b-d4dc-c36448da5633"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0023858\n",
            "\tspeed: 0.0489s/iter; left time: 45.8870s\n",
            "\titers: 200, epoch: 1 | loss: 0.0015158\n",
            "\tspeed: 0.0279s/iter; left time: 23.3669s\n",
            "\titers: 300, epoch: 1 | loss: 0.0021184\n",
            "\tspeed: 0.0326s/iter; left time: 24.0634s\n",
            "\titers: 400, epoch: 1 | loss: 0.0014753\n",
            "\tspeed: 0.0290s/iter; left time: 18.5327s\n",
            "\titers: 500, epoch: 1 | loss: 0.0017113\n",
            "\tspeed: 0.0274s/iter; left time: 14.7173s\n",
            "\titers: 600, epoch: 1 | loss: 0.0016781\n",
            "\tspeed: 0.0289s/iter; left time: 12.6650s\n",
            "\titers: 700, epoch: 1 | loss: 0.0017114\n",
            "\tspeed: 0.0301s/iter; left time: 10.1615s\n",
            "\titers: 800, epoch: 1 | loss: 0.0019008\n",
            "\tspeed: 0.0311s/iter; left time: 7.3921s\n",
            "\titers: 900, epoch: 1 | loss: 0.0014493\n",
            "\tspeed: 0.0272s/iter; left time: 3.7522s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0023661\n",
            "\tspeed: 0.0272s/iter; left time: 1.0348s\n",
            "Epoch: 1 cost time: 32.099430084228516\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0066139 Vali Loss: 0.0110092 Test Loss: 0.0098249\n",
            "Validation loss decreased (inf --> 0.011009).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09915129840373993, mae:0.06940276175737381, r2:0.9869185090065002\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0138773\n",
            "\tspeed: 0.0384s/iter; left time: 35.9939s\n",
            "\titers: 200, epoch: 1 | loss: 0.0049402\n",
            "\tspeed: 0.0281s/iter; left time: 23.5167s\n",
            "\titers: 300, epoch: 1 | loss: 0.0041272\n",
            "\tspeed: 0.0284s/iter; left time: 20.9832s\n",
            "\titers: 400, epoch: 1 | loss: 0.0034991\n",
            "\tspeed: 0.0304s/iter; left time: 19.3683s\n",
            "\titers: 500, epoch: 1 | loss: 0.0022423\n",
            "\tspeed: 0.0314s/iter; left time: 16.8862s\n",
            "\titers: 600, epoch: 1 | loss: 0.0044067\n",
            "\tspeed: 0.0280s/iter; left time: 12.2648s\n",
            "\titers: 700, epoch: 1 | loss: 0.0019791\n",
            "\tspeed: 0.0276s/iter; left time: 9.3210s\n",
            "\titers: 800, epoch: 1 | loss: 0.0033958\n",
            "\tspeed: 0.0284s/iter; left time: 6.7526s\n",
            "\titers: 900, epoch: 1 | loss: 0.0031016\n",
            "\tspeed: 0.0339s/iter; left time: 4.6836s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0010097\n",
            "\tspeed: 0.0278s/iter; left time: 1.0582s\n",
            "Epoch: 1 cost time: 31.37322425842285\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0789084 Vali Loss: 0.0107937 Test Loss: 0.0097614\n",
            "Validation loss decreased (inf --> 0.010794).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09877713769674301, mae:0.06963144987821579, r2:0.987017035484314\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0064418\n",
            "\tspeed: 0.0331s/iter; left time: 31.0506s\n",
            "\titers: 200, epoch: 1 | loss: 0.0051144\n",
            "\tspeed: 0.0331s/iter; left time: 27.7776s\n",
            "\titers: 300, epoch: 1 | loss: 0.0026719\n",
            "\tspeed: 0.0281s/iter; left time: 20.7577s\n",
            "\titers: 400, epoch: 1 | loss: 0.0017486\n",
            "\tspeed: 0.0281s/iter; left time: 17.9546s\n",
            "\titers: 500, epoch: 1 | loss: 0.0032829\n",
            "\tspeed: 0.0287s/iter; left time: 15.4510s\n",
            "\titers: 600, epoch: 1 | loss: 0.0024645\n",
            "\tspeed: 0.0359s/iter; left time: 15.7236s\n",
            "\titers: 700, epoch: 1 | loss: 0.0045960\n",
            "\tspeed: 0.0277s/iter; left time: 9.3566s\n",
            "\titers: 800, epoch: 1 | loss: 0.0014937\n",
            "\tspeed: 0.0278s/iter; left time: 6.6203s\n",
            "\titers: 900, epoch: 1 | loss: 0.0022736\n",
            "\tspeed: 0.0274s/iter; left time: 3.7822s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0047414\n",
            "\tspeed: 0.0338s/iter; left time: 1.2862s\n",
            "Epoch: 1 cost time: 31.550403356552124\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0044206 Vali Loss: 0.0107698 Test Loss: 0.0097351\n",
            "Validation loss decreased (inf --> 0.010770).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09866420924663544, mae:0.07012896239757538, r2:0.9870467185974121\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0037637\n",
            "\tspeed: 0.0310s/iter; left time: 29.0454s\n",
            "\titers: 200, epoch: 1 | loss: 0.0042902\n",
            "\tspeed: 0.0290s/iter; left time: 24.3097s\n",
            "\titers: 300, epoch: 1 | loss: 0.0074288\n",
            "\tspeed: 0.0352s/iter; left time: 25.9431s\n",
            "\titers: 400, epoch: 1 | loss: 0.0020917\n",
            "\tspeed: 0.0275s/iter; left time: 17.5522s\n",
            "\titers: 500, epoch: 1 | loss: 0.0049693\n",
            "\tspeed: 0.0282s/iter; left time: 15.1451s\n",
            "\titers: 600, epoch: 1 | loss: 0.0019915\n",
            "\tspeed: 0.0286s/iter; left time: 12.5258s\n",
            "\titers: 700, epoch: 1 | loss: 0.0032930\n",
            "\tspeed: 0.0350s/iter; left time: 11.8200s\n",
            "\titers: 800, epoch: 1 | loss: 0.0034280\n",
            "\tspeed: 0.0286s/iter; left time: 6.8152s\n",
            "\titers: 900, epoch: 1 | loss: 0.0019198\n",
            "\tspeed: 0.0282s/iter; left time: 3.8875s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0033792\n",
            "\tspeed: 0.0282s/iter; left time: 1.0702s\n",
            "Epoch: 1 cost time: 31.086803436279297\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0047438 Vali Loss: 0.0111768 Test Loss: 0.0098634\n",
            "Validation loss decreased (inf --> 0.011177).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09930907189846039, mae:0.06977744400501251, r2:0.9868768453598022\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0038964\n",
            "\tspeed: 0.0332s/iter; left time: 31.1680s\n",
            "\titers: 200, epoch: 1 | loss: 0.0021544\n",
            "\tspeed: 0.0280s/iter; left time: 23.4411s\n",
            "\titers: 300, epoch: 1 | loss: 0.0026189\n",
            "\tspeed: 0.0278s/iter; left time: 20.5230s\n",
            "\titers: 400, epoch: 1 | loss: 0.0028709\n",
            "\tspeed: 0.0317s/iter; left time: 20.2204s\n",
            "\titers: 500, epoch: 1 | loss: 0.0027251\n",
            "\tspeed: 0.0306s/iter; left time: 16.4552s\n",
            "\titers: 600, epoch: 1 | loss: 0.0020912\n",
            "\tspeed: 0.0277s/iter; left time: 12.1398s\n",
            "\titers: 700, epoch: 1 | loss: 0.0016403\n",
            "\tspeed: 0.0290s/iter; left time: 9.8177s\n",
            "\titers: 800, epoch: 1 | loss: 0.0017604\n",
            "\tspeed: 0.0296s/iter; left time: 7.0406s\n",
            "\titers: 900, epoch: 1 | loss: 0.0033830\n",
            "\tspeed: 0.0319s/iter; left time: 4.4000s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0038786\n",
            "\tspeed: 0.0277s/iter; left time: 1.0541s\n",
            "Epoch: 1 cost time: 30.88957667350769\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0063063 Vali Loss: 0.0112085 Test Loss: 0.0099076\n",
            "Validation loss decreased (inf --> 0.011209).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09954842180013657, mae:0.06988455355167389, r2:0.986813485622406\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0025653\n",
            "\tspeed: 0.0320s/iter; left time: 30.0277s\n",
            "\titers: 200, epoch: 1 | loss: 0.0020725\n",
            "\tspeed: 0.0363s/iter; left time: 30.4225s\n",
            "\titers: 300, epoch: 1 | loss: 0.0034951\n",
            "\tspeed: 0.0279s/iter; left time: 20.5910s\n",
            "\titers: 400, epoch: 1 | loss: 0.0028216\n",
            "\tspeed: 0.0283s/iter; left time: 18.0619s\n",
            "\titers: 500, epoch: 1 | loss: 0.0044774\n",
            "\tspeed: 0.0279s/iter; left time: 15.0200s\n",
            "\titers: 600, epoch: 1 | loss: 0.0039799\n",
            "\tspeed: 0.0347s/iter; left time: 15.1814s\n",
            "\titers: 700, epoch: 1 | loss: 0.0034279\n",
            "\tspeed: 0.0279s/iter; left time: 9.4178s\n",
            "\titers: 800, epoch: 1 | loss: 0.0045677\n",
            "\tspeed: 0.0277s/iter; left time: 6.5815s\n",
            "\titers: 900, epoch: 1 | loss: 0.0018403\n",
            "\tspeed: 0.0274s/iter; left time: 3.7811s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0023527\n",
            "\tspeed: 0.0347s/iter; left time: 1.3185s\n",
            "Epoch: 1 cost time: 31.636317253112793\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0097376 Vali Loss: 0.0112284 Test Loss: 0.0098383\n",
            "Validation loss decreased (inf --> 0.011228).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09922490268945694, mae:0.06906682252883911, r2:0.9868990778923035\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0077363\n",
            "\tspeed: 0.0310s/iter; left time: 29.1206s\n",
            "\titers: 200, epoch: 1 | loss: 0.0038176\n",
            "\tspeed: 0.0282s/iter; left time: 23.6375s\n",
            "\titers: 300, epoch: 1 | loss: 0.0027116\n",
            "\tspeed: 0.0346s/iter; left time: 25.5125s\n",
            "\titers: 400, epoch: 1 | loss: 0.0021105\n",
            "\tspeed: 0.0281s/iter; left time: 17.9494s\n",
            "\titers: 500, epoch: 1 | loss: 0.0018048\n",
            "\tspeed: 0.0277s/iter; left time: 14.9281s\n",
            "\titers: 600, epoch: 1 | loss: 0.0039057\n",
            "\tspeed: 0.0274s/iter; left time: 11.9989s\n",
            "\titers: 700, epoch: 1 | loss: 0.0017247\n",
            "\tspeed: 0.0368s/iter; left time: 12.4460s\n",
            "\titers: 800, epoch: 1 | loss: 0.0017262\n",
            "\tspeed: 0.0283s/iter; left time: 6.7400s\n",
            "\titers: 900, epoch: 1 | loss: 0.0026582\n",
            "\tspeed: 0.0280s/iter; left time: 3.8628s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0025168\n",
            "\tspeed: 0.0278s/iter; left time: 1.0558s\n",
            "Epoch: 1 cost time: 30.9957172870636\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0055483 Vali Loss: 0.0111840 Test Loss: 0.0099101\n",
            "Validation loss decreased (inf --> 0.011184).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09955336153507233, mae:0.06996732950210571, r2:0.986812174320221\n",
            "Đang huấn luyện với tham số: {'batch_size': 32, 'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0063400\n",
            "\tspeed: 0.0351s/iter; left time: 32.9456s\n",
            "\titers: 200, epoch: 1 | loss: 0.0063964\n",
            "\tspeed: 0.0295s/iter; left time: 24.6980s\n",
            "\titers: 300, epoch: 1 | loss: 0.0049236\n",
            "\tspeed: 0.0279s/iter; left time: 20.5652s\n",
            "\titers: 400, epoch: 1 | loss: 0.0110193\n",
            "\tspeed: 0.0316s/iter; left time: 20.1493s\n",
            "\titers: 500, epoch: 1 | loss: 0.0021532\n",
            "\tspeed: 0.0305s/iter; left time: 16.3848s\n",
            "\titers: 600, epoch: 1 | loss: 0.0064810\n",
            "\tspeed: 0.0278s/iter; left time: 12.1599s\n",
            "\titers: 700, epoch: 1 | loss: 0.0038354\n",
            "\tspeed: 0.0283s/iter; left time: 9.5663s\n",
            "\titers: 800, epoch: 1 | loss: 0.0025689\n",
            "\tspeed: 0.0300s/iter; left time: 7.1308s\n",
            "\titers: 900, epoch: 1 | loss: 0.0012453\n",
            "\tspeed: 0.0326s/iter; left time: 4.5009s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0018705\n",
            "\tspeed: 0.0276s/iter; left time: 1.0478s\n",
            "Epoch: 1 cost time: 31.279781341552734\n",
            "Epoch: 1, Steps: 1037 | Train Loss: 0.0060598 Vali Loss: 0.0111762 Test Loss: 0.0100377\n",
            "Validation loss decreased (inf --> 0.011176).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.100237175822258, mae:0.07028652727603912, r2:0.986630380153656\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0030890\n",
            "\tspeed: 0.0346s/iter; left time: 14.4948s\n",
            "\titers: 200, epoch: 1 | loss: 0.0031583\n",
            "\tspeed: 0.0331s/iter; left time: 10.5535s\n",
            "\titers: 300, epoch: 1 | loss: 0.0022574\n",
            "\tspeed: 0.0290s/iter; left time: 6.3495s\n",
            "\titers: 400, epoch: 1 | loss: 0.0023296\n",
            "\tspeed: 0.0288s/iter; left time: 3.4293s\n",
            "\titers: 500, epoch: 1 | loss: 0.0026190\n",
            "\tspeed: 0.0299s/iter; left time: 0.5688s\n",
            "Epoch: 1 cost time: 16.40965509414673\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0182795 Vali Loss: 0.0110839 Test Loss: 0.0099504\n",
            "Validation loss decreased (inf --> 0.011084).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.0997811108827591, mae:0.06976287811994553, r2:0.9867517948150635\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0046164\n",
            "\tspeed: 0.0381s/iter; left time: 15.9626s\n",
            "\titers: 200, epoch: 1 | loss: 0.0027347\n",
            "\tspeed: 0.0298s/iter; left time: 9.5189s\n",
            "\titers: 300, epoch: 1 | loss: 0.0021950\n",
            "\tspeed: 0.0289s/iter; left time: 6.3343s\n",
            "\titers: 400, epoch: 1 | loss: 0.0027888\n",
            "\tspeed: 0.0285s/iter; left time: 3.3931s\n",
            "\titers: 500, epoch: 1 | loss: 0.0028415\n",
            "\tspeed: 0.0327s/iter; left time: 0.6216s\n",
            "Epoch: 1 cost time: 16.74382472038269\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0316243 Vali Loss: 0.0110134 Test Loss: 0.0099976\n",
            "Validation loss decreased (inf --> 0.011013).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09998925030231476, mae:0.07080055773258209, r2:0.9866964817047119\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0037784\n",
            "\tspeed: 0.0415s/iter; left time: 17.3737s\n",
            "\titers: 200, epoch: 1 | loss: 0.0019052\n",
            "\tspeed: 0.0281s/iter; left time: 8.9681s\n",
            "\titers: 300, epoch: 1 | loss: 0.0026981\n",
            "\tspeed: 0.0288s/iter; left time: 6.3166s\n",
            "\titers: 400, epoch: 1 | loss: 0.0021932\n",
            "\tspeed: 0.0287s/iter; left time: 3.4140s\n",
            "\titers: 500, epoch: 1 | loss: 0.0022236\n",
            "\tspeed: 0.0346s/iter; left time: 0.6580s\n",
            "Epoch: 1 cost time: 16.82407808303833\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0040853 Vali Loss: 0.0111078 Test Loss: 0.0098710\n",
            "Validation loss decreased (inf --> 0.011108).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09941888600587845, mae:0.06985177099704742, r2:0.9868478178977966\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.2, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0052326\n",
            "\tspeed: 0.0398s/iter; left time: 16.6634s\n",
            "\titers: 200, epoch: 1 | loss: 0.0038584\n",
            "\tspeed: 0.0300s/iter; left time: 9.5637s\n",
            "\titers: 300, epoch: 1 | loss: 0.0055063\n",
            "\tspeed: 0.0282s/iter; left time: 6.1711s\n",
            "\titers: 400, epoch: 1 | loss: 0.0031719\n",
            "\tspeed: 0.0282s/iter; left time: 3.3605s\n",
            "\titers: 500, epoch: 1 | loss: 0.0036970\n",
            "\tspeed: 0.0352s/iter; left time: 0.6681s\n",
            "Epoch: 1 cost time: 16.802027702331543\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0092269 Vali Loss: 0.0113548 Test Loss: 0.0100104\n",
            "Validation loss decreased (inf --> 0.011355).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.10011212527751923, mae:0.07064162194728851, r2:0.9866637587547302\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0020041\n",
            "\tspeed: 0.0402s/iter; left time: 16.8444s\n",
            "\titers: 200, epoch: 1 | loss: 0.0035132\n",
            "\tspeed: 0.0280s/iter; left time: 8.9336s\n",
            "\titers: 300, epoch: 1 | loss: 0.0038019\n",
            "\tspeed: 0.0283s/iter; left time: 6.2079s\n",
            "\titers: 400, epoch: 1 | loss: 0.0021809\n",
            "\tspeed: 0.0303s/iter; left time: 3.6050s\n",
            "\titers: 500, epoch: 1 | loss: 0.0016948\n",
            "\tspeed: 0.0345s/iter; left time: 0.6559s\n",
            "Epoch: 1 cost time: 16.80217719078064\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0085000 Vali Loss: 0.0112382 Test Loss: 0.0100428\n",
            "Validation loss decreased (inf --> 0.011238).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.10027293115854263, mae:0.0704401507973671, r2:0.9866208434104919\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.01, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0042179\n",
            "\tspeed: 0.0409s/iter; left time: 17.1458s\n",
            "\titers: 200, epoch: 1 | loss: 0.0032994\n",
            "\tspeed: 0.0283s/iter; left time: 9.0398s\n",
            "\titers: 300, epoch: 1 | loss: 0.0021337\n",
            "\tspeed: 0.0286s/iter; left time: 6.2582s\n",
            "\titers: 400, epoch: 1 | loss: 0.0020211\n",
            "\tspeed: 0.0302s/iter; left time: 3.5919s\n",
            "\titers: 500, epoch: 1 | loss: 0.0016268\n",
            "\tspeed: 0.0338s/iter; left time: 0.6428s\n",
            "Epoch: 1 cost time: 16.880229949951172\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0282635 Vali Loss: 0.0113043 Test Loss: 0.0105740\n",
            "Validation loss decreased (inf --> 0.011304).  Saving model ...\n",
            "Updating learning rate to 0.01\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.10276288539171219, mae:0.07562942057847977, r2:0.9859481453895569\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_units': 32}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 32, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0069202\n",
            "\tspeed: 0.0353s/iter; left time: 14.7738s\n",
            "\titers: 200, epoch: 1 | loss: 0.0038286\n",
            "\tspeed: 0.0282s/iter; left time: 8.9928s\n",
            "\titers: 300, epoch: 1 | loss: 0.0035086\n",
            "\tspeed: 0.0285s/iter; left time: 6.2465s\n",
            "\titers: 400, epoch: 1 | loss: 0.0033758\n",
            "\tspeed: 0.0330s/iter; left time: 3.9237s\n",
            "\titers: 500, epoch: 1 | loss: 0.0027428\n",
            "\tspeed: 0.0303s/iter; left time: 0.5753s\n",
            "Epoch: 1 cost time: 16.220890760421753\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0082751 Vali Loss: 0.0111940 Test Loss: 0.0101304\n",
            "Validation loss decreased (inf --> 0.011194).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm32_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.10064896941184998, mae:0.07214746624231339, r2:0.9865203499794006\n",
            "Đang huấn luyện với tham số: {'batch_size': 64, 'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_units': 64}\n",
            "Args in experiment:\n",
            "{'target': 'q64', 'des': 'Exp', 'dropout': 0.5, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': './checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'seq_len': 24, 'label_len': 24, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'd_model': 64, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.001, 'batch_size': 64, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 1, 'is_training': True, 'enc_in': 1, 'dec_in': 1, 'c_out': 1, 'root_path': './dataset', 'data_path': 'mucnuoc_gio_preprocess1.csv', 'model_id': 'q64', 'model': 'Autoformer', 'data': 'custom', 'features': 'S'}\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 33205\n",
            "val 4728\n",
            "test 9477\n",
            "\titers: 100, epoch: 1 | loss: 0.0050841\n",
            "\tspeed: 0.0331s/iter; left time: 13.8818s\n",
            "\titers: 200, epoch: 1 | loss: 0.0040440\n",
            "\tspeed: 0.0283s/iter; left time: 9.0265s\n",
            "\titers: 300, epoch: 1 | loss: 0.0030667\n",
            "\tspeed: 0.0282s/iter; left time: 6.1747s\n",
            "\titers: 400, epoch: 1 | loss: 0.0027759\n",
            "\tspeed: 0.0342s/iter; left time: 4.0642s\n",
            "\titers: 500, epoch: 1 | loss: 0.0017956\n",
            "\tspeed: 0.0291s/iter; left time: 0.5529s\n",
            "Epoch: 1 cost time: 15.965100049972534\n",
            "Epoch: 1, Steps: 518 | Train Loss: 0.0071351 Vali Loss: 0.0111551 Test Loss: 0.0099801\n",
            "Validation loss decreased (inf --> 0.011155).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            ">>>>>>>testing : q64_Autoformer_custom_ftS_sl24_ll24_pl24_dm64_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 9477\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "test shape: (9477, 24, 1) (9477, 24, 1)\n",
            "rmse:0.09992745518684387, mae:0.07074269652366638, r2:0.9867128729820251\n",
            "Best Parameters: ({'batch_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_units': 32}, np.float32(0.09866421), np.float32(0.9870467))\n",
            "Best Parameters: ({'batch_size': 64, 'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_units': 64}, np.float32(0.102762885), np.float32(0.98594815))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvz-Lr1A-d-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qo9RqUQD-eBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5GNp74S-eDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21Mnh8_s-eG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeRce1aT-eQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Nrcr5-g-eS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ra04pklS-eWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"tatrach-autoformer-main\")"
      ],
      "metadata": {
        "id": "sq8sHivD9nMu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2f5b16f8-70c2-4beb-8822-0b16bbd9eb3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'tatrach-autoformer-main'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2153837708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tatrach-autoformer-main\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tatrach-autoformer-main'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# In ra thư mục hiện tại\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# Liệt kê toàn bộ file/thư mục trong thư mục hiện tại\n",
        "print(\"Files here:\", os.listdir(\".\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK7s_S949ZVa",
        "outputId": "72bf7b9e-7d46-450e-cc1c-b25e800e2efa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/tatrach-autoformer-main\n",
            "Files here: ['exp', 'run.py', 'utils', 'layers', 'predict.ipynb', 'pic', 'environment.yml', 'dataset', '.gitignore', 'tatrach.rar', 'Dockerfile', 'README.md', 'tatrach.ipynb', 'models', 'LICENSE', 'Makefile', 'data_provider', 'requirements.txt', 'scripts']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86cb3d5e",
        "outputId": "0e604c2c-ccbb-4e49-ed33-93d3d2c3716e"
      },
      "source": [
        "with open('exp/exp_main.py', 'r') as f:\n",
        "    print(f.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import logging\n",
            "logging.basicConfig(format='%(asctime)s,%(msecs)03d %(levelname)-8s [%(filename)s:%(lineno)d] %(message)s',\n",
            "    datefmt='%Y-%m-%d:%H:%M:%S',\n",
            "    level=logging.INFO)\n",
            "\n",
            "from data_provider.data_factory import data_provider\n",
            "from exp.exp_basic import Exp_Basic\n",
            "from models import Informer, Autoformer, Transformer, Reformer\n",
            "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
            "from utils.metrics import metric\n",
            "\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "from torch import optim\n",
            "\n",
            "import os\n",
            "import time\n",
            "\n",
            "import warnings\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "\n",
            "class Exp_Main(Exp_Basic):\n",
            "    def __init__(self, args):\n",
            "        super(Exp_Main, self).__init__(args)\n",
            "\n",
            "    def _build_model(self):\n",
            "        model_dict = {\n",
            "            'Autoformer': Autoformer,\n",
            "            'Transformer': Transformer,\n",
            "            'Informer': Informer,\n",
            "            'Reformer': Reformer,\n",
            "        }\n",
            "        model = model_dict[self.args.model].Model(self.args).float()\n",
            "\n",
            "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
            "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
            "        return model\n",
            "\n",
            "    def _get_data(self, flag):\n",
            "        data_set, data_loader = data_provider(self.args, flag)\n",
            "        return data_set, data_loader\n",
            "\n",
            "    def _select_optimizer(self):\n",
            "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
            "        return model_optim\n",
            "\n",
            "    def _select_criterion(self):\n",
            "        criterion = nn.MSELoss()\n",
            "        return criterion\n",
            "\n",
            "    def _predict(self, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
            "        # decoder input\n",
            "        dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
            "        dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
            "        # encoder - decoder\n",
            "\n",
            "        def _run_model():\n",
            "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
            "            if self.args.output_attention:\n",
            "                outputs = outputs[0]\n",
            "            return outputs\n",
            "\n",
            "        if self.args.use_amp:\n",
            "            with torch.cuda.amp.autocast():\n",
            "                outputs = _run_model()\n",
            "        else:\n",
            "            outputs = _run_model()\n",
            "\n",
            "        f_dim = -1 if self.args.features == 'MS' else 0\n",
            "        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
            "        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
            "\n",
            "        return outputs, batch_y\n",
            "\n",
            "    def vali(self, vali_data, vali_loader, criterion):\n",
            "        total_loss = []\n",
            "        self.model.eval()\n",
            "        with torch.no_grad():\n",
            "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
            "                batch_x = batch_x.float().to(self.device)\n",
            "                batch_y = batch_y.float()\n",
            "\n",
            "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
            "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
            "\n",
            "                outputs, batch_y = self._predict(batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
            "\n",
            "                pred = outputs.detach().cpu()\n",
            "                true = batch_y.detach().cpu()\n",
            "\n",
            "                loss = criterion(pred, true)\n",
            "\n",
            "                total_loss.append(loss)\n",
            "        total_loss = np.average(total_loss)\n",
            "        self.model.train()\n",
            "        return total_loss\n",
            "\n",
            "    def train(self, setting):\n",
            "        train_data, train_loader = self._get_data(flag='train')\n",
            "        vali_data, vali_loader = self._get_data(flag='val')\n",
            "        test_data, test_loader = self._get_data(flag='test')\n",
            "\n",
            "        path = os.path.join(self.args.checkpoints, setting)\n",
            "        if not os.path.exists(path):\n",
            "            os.makedirs(path)\n",
            "\n",
            "        time_now = time.time()\n",
            "\n",
            "        train_steps = len(train_loader)\n",
            "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
            "\n",
            "        model_optim = self._select_optimizer()\n",
            "        criterion = self._select_criterion()\n",
            "\n",
            "        if self.args.use_amp:\n",
            "            scaler = torch.cuda.amp.GradScaler()\n",
            "\n",
            "        for epoch in range(self.args.train_epochs):\n",
            "            iter_count = 0\n",
            "            train_loss = []\n",
            "\n",
            "            self.model.train()\n",
            "            epoch_time = time.time()\n",
            "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
            "                iter_count += 1\n",
            "                model_optim.zero_grad()\n",
            "                batch_x = batch_x.float().to(self.device)\n",
            "\n",
            "                batch_y = batch_y.float().to(self.device)\n",
            "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
            "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
            "\n",
            "                outputs, batch_y = self._predict(batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
            "\n",
            "                loss = criterion(outputs, batch_y)\n",
            "                train_loss.append(loss.item())\n",
            "\n",
            "                if (i + 1) % 100 == 0:\n",
            "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
            "                    speed = (time.time() - time_now) / iter_count\n",
            "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
            "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
            "                    iter_count = 0\n",
            "                    time_now = time.time()\n",
            "\n",
            "                if self.args.use_amp:\n",
            "                    scaler.scale(loss).backward()\n",
            "                    scaler.step(model_optim)\n",
            "                    scaler.update()\n",
            "                else:\n",
            "                    loss.backward()\n",
            "                    model_optim.step()\n",
            "\n",
            "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
            "            train_loss = np.average(train_loss)\n",
            "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
            "            test_loss = self.vali(test_data, test_loader, criterion)\n",
            "\n",
            "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
            "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
            "            early_stopping(vali_loss, self.model, path)\n",
            "            if early_stopping.early_stop:\n",
            "                print(\"Early stopping\")\n",
            "                break\n",
            "\n",
            "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
            "\n",
            "        best_model_path = path + '/' + 'checkpoint.pth'\n",
            "        self.model.load_state_dict(torch.load(best_model_path))\n",
            "\n",
            "        return\n",
            "\n",
            "    def test(self, setting, test=0):\n",
            "        test_data, test_loader = self._get_data(flag='test')\n",
            "        if test:\n",
            "            print('loading model')\n",
            "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
            "\n",
            "        preds = []\n",
            "        trues = []\n",
            "        folder_path = './test_results/' + setting + '/'\n",
            "        if not os.path.exists(folder_path):\n",
            "            os.makedirs(folder_path)\n",
            "\n",
            "        self.model.eval()\n",
            "        with torch.no_grad():\n",
            "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
            "                batch_x = batch_x.float().to(self.device)\n",
            "                batch_y = batch_y.float().to(self.device)\n",
            "\n",
            "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
            "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
            "\n",
            "                outputs, batch_y = self._predict(batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
            "\n",
            "                outputs = outputs.detach().cpu().numpy()\n",
            "                batch_y = batch_y.detach().cpu().numpy()\n",
            "\n",
            "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
            "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
            "\n",
            "                preds.append(pred)\n",
            "                trues.append(true)\n",
            "                if i % 20 == 0:\n",
            "                    input = batch_x.detach().cpu().numpy()\n",
            "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
            "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
            "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
            "\n",
            "        preds = np.concatenate(preds, axis=0)\n",
            "        trues = np.concatenate(trues, axis=0)\n",
            "        print('test shape:', preds.shape, trues.shape)\n",
            "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
            "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
            "        print('test shape:', preds.shape, trues.shape)\n",
            "\n",
            "        # result save\n",
            "        folder_path = './results/' + setting + '/'\n",
            "        if not os.path.exists(folder_path):\n",
            "            os.makedirs(folder_path)\n",
            "\n",
            "        mae, mse, rmse, mape, mspe, r2 = metric(preds, trues)\n",
            "        print(\"aaaaaaaaaaaaaa\", r2)\n",
            "        print('mse:{}, mae:{}, r2:{}'.format(mse, mae, r2))\n",
            "        f = open(\"result.txt\", 'a')\n",
            "        f.write(setting + \"  \\n\")\n",
            "        f.write('mse:{}, mae:{}, r2:{}'.format(mse, mae, r2))\n",
            "        f.write('\\n')\n",
            "        f.write('\\n')\n",
            "        f.close()\n",
            "\n",
            "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe, r2]))\n",
            "        np.save(folder_path + 'pred.npy', preds)\n",
            "        np.save(folder_path + 'true.npy', trues)\n",
            "        \n",
            "\n",
            "        return mae, rmse, r2\n",
            "\n",
            "    def predict(self, setting, load=False):\n",
            "        pred_data, pred_loader = self._get_data(flag='pred')\n",
            "\n",
            "        if load:\n",
            "            path = os.path.join(self.args.checkpoints, setting)\n",
            "            best_model_path = path + '/' + 'checkpoint.pth'\n",
            "            logging.info(best_model_path)\n",
            "            self.model.load_state_dict(torch.load(best_model_path))\n",
            "\n",
            "        preds = []\n",
            "\n",
            "        self.model.eval()\n",
            "        with torch.no_grad():\n",
            "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
            "                batch_x = batch_x.float().to(self.device)\n",
            "                batch_y = batch_y.float()\n",
            "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
            "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
            "\n",
            "                outputs, batch_y = self._predict(batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
            "\n",
            "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
            "                preds.append(pred)\n",
            "\n",
            "        preds = np.array(preds)\n",
            "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
            "\n",
            "        # result save\n",
            "        folder_path = './results/' + setting + '/'\n",
            "        if not os.path.exists(folder_path):\n",
            "            os.makedirs(folder_path)\n",
            "\n",
            "        np.save(folder_path + 'real_prediction.npy', preds)\n",
            "\n",
            "        return\n",
            "\n"
          ]
        }
      ]
    }
  ]
}